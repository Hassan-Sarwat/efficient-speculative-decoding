model_name: "unsloth/Qwen2.5-14B-Instruct"
final_save_path: "models/target"
data_file: "data/processed/cot_easy.jsonl"
load_in_4bit: true
max_seq_length: 1536

# Data Splitting
val_split_ratio: 0.1      
random_seed: 42           

# LoRA Arguments
lora_r: 16
lora_alpha: 16
lora_dropout: 0
lora_target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]

# Training Arguments
output_dir: "checkpoints_target"
per_device_train_batch_size: 2
gradient_accumulation_steps: 4
learning_rate: 2.0e-4
num_train_epochs: 3
optim: "adamw_8bit"
logging_steps: 1